{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_file = 'AM_IM_SS_New_AM9.csv'\n",
    "num_of_feature = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = np.zeros([163, num_of_feature+3])\n",
    "ternary = np.zeros([120, num_of_feature+3])\n",
    "quaternary = np.zeros([89, num_of_feature+3])\n",
    "highorder = np.zeros([229, num_of_feature+3])\n",
    "c2 = 0\n",
    "c3 = 0\n",
    "c4 = 0\n",
    "c5 = 0\n",
    "file = open(data_file, mode='r')\n",
    "lines = file.readlines()\n",
    "for i, l in enumerate(lines):\n",
    "    data = l.split(',')\n",
    "    if int(data[1]) == 2:   # 这里data[1]第二列就是该训练样本的元素个数，把几元金属分开\n",
    "        for j, d in enumerate(data):\n",
    "            if j >= 4 and j <= num_of_feature+3:   # 这里为什么是从4开始呢？因为第5列开始才是数据特征\n",
    "                        # 第一列是化学式alloy、第二列是元素个数No、第三列是元素种类component 第四列是元素个数比fraction\n",
    "                binary[c2][j-4] = float(d)\n",
    "            elif j >= num_of_feature+6 and j<= num_of_feature+8:    # num_of_featire + 6 列到 8 是AM IM SS 应该是标签\n",
    "                binary[c2][j-6] = int(d)\n",
    "        c2+=1\n",
    "    elif int(data[1]) == 3:\n",
    "        for j, d in enumerate(data):\n",
    "            if j >= 4 and j <= num_of_feature+3:\n",
    "                ternary[c3][j-4] = float(d)\n",
    "            elif j >= num_of_feature+6 and j<= num_of_feature+8:\n",
    "                ternary[c3][j-6] = int(d)\n",
    "        c3+=1\n",
    "    elif int(data[1]) == 4:\n",
    "        for j, d in enumerate(data):\n",
    "            if j >= 4 and j <= num_of_feature+3:\n",
    "                quaternary[c4][j-4] = float(d)\n",
    "            elif j >= num_of_feature+6 and j<= num_of_feature+8:\n",
    "                quaternary[c4][j-6] = int(d)\n",
    "        c4+=1\n",
    "    else:\n",
    "        for j, d in enumerate(data):\n",
    "            if j >= 4 and j <= num_of_feature+3:\n",
    "                highorder[c5][j-4] = float(d)\n",
    "            elif j >= num_of_feature+6 and j<= num_of_feature+8:\n",
    "                highorder[c5][j-6] = int(d)\n",
    "        c5+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 163 is out of bounds for axis 0 with size 163",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7ad7b8d17c55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcollect_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mc2\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 163 is out of bounds for axis 0 with size 163"
     ]
    }
   ],
   "source": [
    "# def collect_data(data,array):\n",
    "#     for j,d in enumerate(data):\n",
    "#         if 4 <= j <= num_of_feature+3:\n",
    "#             array[j-4] = float(d)\n",
    "#         elif num_of_feature+6 <= j <= num_of_feature+8:\n",
    "#             array[j-6] = int(d)\n",
    "            \n",
    "# if int(data[1]) == 2:\n",
    "#     collect_data(data,binary[c2,:])\n",
    "#     c2 += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0, 10):\n",
    "    np.random.shuffle(binary)\n",
    "    np.random.shuffle(ternary)\n",
    "    np.random.shuffle(quaternary)\n",
    "    np.random.shuffle(highorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate((binary[:114], ternary[:84], quaternary[:62], highorder[:160]))\n",
    "val_data = np.concatenate((binary[114:139], ternary[84:102], quaternary[62:76], highorder[160:194]))\n",
    "test_data = np.concatenate((binary[139:], ternary[102:], quaternary[76:], highorder[194:]))\n",
    "x_train = train_data[:, :num_of_feature]\n",
    "y_train_AM = np.squeeze(train_data[:, num_of_feature: num_of_feature+1])\n",
    "y_train_IM = np.squeeze(train_data[:, num_of_feature+1: num_of_feature+2])\n",
    "y_train_SS = np.squeeze(train_data[:, num_of_feature+2: num_of_feature+3])\n",
    "x_val = val_data[:, :num_of_feature]\n",
    "y_val_AM = np.squeeze(val_data[:, num_of_feature: num_of_feature+1])\n",
    "y_val_IM = np.squeeze(val_data[:, num_of_feature+1: num_of_feature+2])\n",
    "y_val_SS = np.squeeze(val_data[:, num_of_feature+2: num_of_feature+3])\n",
    "x_test = test_data[:, :num_of_feature]\n",
    "y_test_AM = np.squeeze(test_data[:, num_of_feature: num_of_feature+1])\n",
    "y_test_IM = np.squeeze(test_data[:, num_of_feature+1: num_of_feature+2])\n",
    "y_test_SS = np.squeeze(test_data[:, num_of_feature+2: num_of_feature+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里就这样把，因为他是把二元金属各种都是按照比例划分然后在合并的，所以就这样也行，主要还是简化一下label的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>什么玩意儿？代码能写得更烂吗</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open('data/data_pred.npy', mode='r')\n",
    "# data_pred = np.zeros([8, num_of_feature])\n",
    "# lines = file.readlines()\n",
    "# for i, l in enumerate(lines):\n",
    "#     data = l.split(',')\n",
    "#     for j, d in enumerate(data):\n",
    "#         if j >= 4 and j <= num_of_feature+3:\n",
    "#             data_pred[i][j-4] = float(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化 修改版\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_trian = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "X_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.squeeze(train_data[:,-3:-1])\n",
    "y_val = np.squeeze(val_data[:,-3:-1])\n",
    "y_test = np.squeeze(test_data[:,-3:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = np.mean(x_train, axis=0)\n",
    "# std = np.std(x_train, axis=0)\n",
    "# x_train = (x_train - mean) / std\n",
    "# x_val = (x_val - mean) / std\n",
    "# x_test = (x_test - mean) / std\n",
    "# data_pred = (data_pred - mean) / std\n",
    "# train_stat = [mean, std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/x_train_' + str(num_of_feature) +'_demo', x_train)\n",
    "np.save('data/y_train_AM_' + str(num_of_feature) +'_demo', y_train[0])\n",
    "np.save('data/y_train_IM_' + str(num_of_feature) +'_demo', y_train[1])\n",
    "np.save('data/y_train_SS_' + str(num_of_feature) +'_demo', y_train[2])\n",
    "np.save('data/x_val_' + str(num_of_feature) +'_demo', x_val)\n",
    "np.save('data/y_val_AM_' + str(num_of_feature) +'_demo', y_val[0])\n",
    "np.save('data/y_val_IM_' + str(num_of_feature) +'_demo', y_val[1])\n",
    "np.save('data/y_val_SS_' + str(num_of_feature) +'_demo', y_val[2])\n",
    "np.save('data/x_test_' + str(num_of_feature) +'_demo', x_test)\n",
    "np.save('data/y_test_AM_' + str(num_of_feature) +'_demo', y_test[0])\n",
    "np.save('data/y_test_IM_' + str(num_of_feature) +'_demo', y_test[1])\n",
    "np.save('data/y_test_SS_' + str(num_of_feature) +'_demo', y_test[2])\n",
    "# np.save('data/train_stat_' + str(num_of_feature) +'_demo', train_stat)\n",
    "# np.save('data/for_pred' + str(num_of_feature) +'_demo', data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/x_train_' + str(num_of_feature) +'_demo', x_train)\n",
    "np.save('data/y_train_' + str(num_of_feature) +'_demo', y_train)\n",
    "np.save('data/x_val_' + str(num_of_feature) +'_demo', x_val)\n",
    "np.save('data/y_val_' + str(num_of_feature) +'_demo', y_val)\n",
    "np.save('data/x_test_' + str(num_of_feature) +'_demo', x_test)\n",
    "np.save('data/y_test_' + str(num_of_feature) +'_demo', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('data/x_train_' + str(num_of_feature) +'_revise', x_train)\n",
    "# np.save('data/y_train_AM_' + str(num_of_feature) +'_revise', y_train_AM)\n",
    "# np.save('data/y_train_IM_' + str(num_of_feature) +'_revise', y_train_IM)\n",
    "# np.save('data/y_train_SS_' + str(num_of_feature) +'_revise', y_train_SS)\n",
    "# np.save('data/x_val_' + str(num_of_feature) +'_revise', x_val)\n",
    "# np.save('data/y_val_AM_' + str(num_of_feature) +'_revise', y_val_AM)\n",
    "# np.save('data/y_val_IM_' + str(num_of_feature) +'_revise', y_val_IM)\n",
    "# np.save('data/y_val_SS_' + str(num_of_feature) +'_revise', y_val_SS)\n",
    "# np.save('data/x_test_' + str(num_of_feature) +'_revise', x_test)\n",
    "# np.save('data/y_test_AM_' + str(num_of_feature) +'_revise', y_test_AM)\n",
    "# np.save('data/y_test_IM_' + str(num_of_feature) +'_revise', y_test_IM)\n",
    "# np.save('data/y_test_SS_' + str(num_of_feature) +'_revise', y_test_SS)\n",
    "# np.save('data/train_stat_' + str(num_of_feature) +'_revise', train_stat)\n",
    "# np.save('data/for_pred' + str(num_of_feature) +'_revise', data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "148px",
    "width": "253px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
